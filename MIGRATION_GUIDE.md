# OpenVLA è¿ç§»æŒ‡å— - æ–‡ä»¶è·¯å¾„æ±‡æ€»

## ğŸ“‚ é¡¹ç›®æ–‡ä»¶ç»“æ„

### æ ¸å¿ƒé¡¹ç›®è·¯å¾„
```
é¡¹ç›®æ ¹ç›®å½•: d:\Stazica\Documents\GitHub\openvla
```

---

## ğŸ“¦ å…³é”®æ–‡ä»¶å’Œç›®å½•

### 1. æ¨¡å‹æ–‡ä»¶ï¼ˆå·²ä¸‹è½½å®Œæˆï¼‰

**æœ¬åœ°æ¨¡å‹è·¯å¾„**:
```
d:\Stazica\Documents\GitHub\openvla\huggingface\
```

**æ¨¡å‹æ–‡ä»¶æ¸…å•** (14.04 GB):
```
d:\Stazica\Documents\GitHub\openvla\huggingface\
â”œâ”€â”€ config.json                                    (é…ç½®æ–‡ä»¶)
â”œâ”€â”€ generation_config.json                         (ç”Ÿæˆé…ç½®)
â”œâ”€â”€ model.safetensors.index.json                  (æƒé‡ç´¢å¼•)
â”œâ”€â”€ model-00001-of-00003.safetensors              (6.47 GB)
â”œâ”€â”€ model-00002-of-00003.safetensors              (6.49 GB)
â”œâ”€â”€ model-00003-of-00003.safetensors              (1.08 GB)
â”œâ”€â”€ configuration_prismatic.py                     (æ¨¡å‹é…ç½®ç±»)
â”œâ”€â”€ modeling_prismatic.py                          (æ¨¡å‹å®šä¹‰)
â”œâ”€â”€ preprocessor_config.json                      (é¢„å¤„ç†å™¨é…ç½®)
â”œâ”€â”€ processor_config.json                         (å¤„ç†å™¨é…ç½®)
â”œâ”€â”€ processing_prismatic.py                        (å¤„ç†é€»è¾‘)
â”œâ”€â”€ tokenizer.json                                (Tokenizer è¯è¡¨)
â”œâ”€â”€ tokenizer.model                               (Tokenizer æ¨¡å‹)
â”œâ”€â”€ tokenizer_config.json                         (Tokenizer é…ç½®)
â”œâ”€â”€ special_tokens_map.json                       (ç‰¹æ®Š token æ˜ å°„)
â””â”€â”€ added_tokens.json                             (è‡ªå®šä¹‰ token)
```

**è¿ç§»æç¤º**:
- å°† `huggingface/` æ•´ä¸ªç›®å½•å¤åˆ¶åˆ°ä½ çš„æ–°é¡¹ç›®
- æˆ–è€…åœ¨ä»£ç ä¸­ä½¿ç”¨ç»å¯¹è·¯å¾„åŠ è½½æ¨¡å‹

---

### 2. æ¨ç†è„šæœ¬

**å·²åˆ›å»ºçš„æ¼”ç¤ºè„šæœ¬**:

| æ–‡ä»¶ | è·¯å¾„ | ç”¨é€” |
|------|------|------|
| `demo_local.py` | `d:\Stazica\Documents\GitHub\openvla\demo_local.py` | æœ¬åœ°æ¨¡å‹æ¨ç†æ¼”ç¤ºï¼ˆå·²æµ‹è¯•æˆåŠŸï¼‰ |
| `demo_custom.py` | `d:\Stazica\Documents\GitHub\openvla\demo_custom.py` | è‡ªå®šä¹‰å›¾åƒæ¨ç† |
| `simple_test.py` | `d:\Stazica\Documents\GitHub\openvla\simple_test.py` | åŸºç¡€ç¯å¢ƒæµ‹è¯• |
| `test_env.py` | `d:\Stazica\Documents\GitHub\openvla\test_env.py` | å®Œæ•´ç¯å¢ƒæµ‹è¯• |

**ä½¿ç”¨ç¤ºä¾‹**:
```bash
cd d:\Stazica\Documents\GitHub\openvla

# è¿è¡Œæœ¬åœ°æ¼”ç¤º
python demo_local.py

# ä½¿ç”¨è‡ªå®šä¹‰å›¾åƒ
python demo_custom.py --image "path/to/your/image.jpg" --instruction "pick up the object"
```

---

### 3. æ ¸å¿ƒæºä»£ç 

#### 3.1 Prismatic åŒ…ï¼ˆVLA å®ç°ï¼‰
```
d:\Stazica\Documents\GitHub\openvla\prismatic\
```

**å…³é”®å­ç›®å½•**:

| å­ç›®å½• | è·¯å¾„ | ç”¨é€” |
|--------|------|------|
| `conf/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\conf\` | é…ç½®æ–‡ä»¶ï¼ˆYAMLï¼‰ |
| `extern/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\extern\` | å¤–éƒ¨æ¥å£ï¼ˆHuggingFace é›†æˆï¼‰ |
| `models/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\models\` | æ¨¡å‹å®šä¹‰ï¼ˆ29 ä¸ªæ–‡ä»¶ï¼‰ |
| `vla/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\vla\` | VLA ç›¸å…³ä»£ç ï¼ˆ19 ä¸ªæ–‡ä»¶ï¼‰ |
| `preprocessing/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\preprocessing\` | æ•°æ®é¢„å¤„ç† |
| `training/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\training\` | è®­ç»ƒå·¥å…· |
| `util/` | `d:\Stazica\Documents\GitHub\openvla\prismatic\util\` | é€šç”¨å·¥å…· |

**è¿ç§»å¿…éœ€æ–‡ä»¶**:
```
# æ ¸å¿ƒæ¨¡å‹å®ç°
d:\Stazica\Documents\GitHub\openvla\prismatic\models\

# VLA åŠŸèƒ½
d:\Stazica\Documents\GitHub\openvla\prismatic\vla\

# HuggingFace æ¥å£
d:\Stazica\Documents\GitHub\openvla\prismatic\extern\hf\

# é…ç½®æ–‡ä»¶
d:\Stazica\Documents\GitHub\openvla\prismatic\conf\
```

#### 3.2 VLA è„šæœ¬ï¼ˆè®­ç»ƒ/å¾®è°ƒ/éƒ¨ç½²ï¼‰
```
d:\Stazica\Documents\GitHub\openvla\vla-scripts\
```

| æ–‡ä»¶ | è·¯å¾„ | ç”¨é€” |
|------|------|------|
| `train.py` | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\train.py` | å®Œæ•´æ¨¡å‹è®­ç»ƒ |
| `finetune.py` | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\finetune.py` | LoRA å¾®è°ƒè„šæœ¬ |
| `deploy.py` | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\deploy.py` | REST API éƒ¨ç½² |
| `extern/` | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\extern\` | å¤–éƒ¨å·¥å…· |

**è¿ç§»å¿…éœ€æ–‡ä»¶**:
```python
# æ¨ç†å’Œéƒ¨ç½²
d:\Stazica\Documents\GitHub\openvla\vla-scripts\deploy.py

# å¾®è°ƒ
d:\Stazica\Documents\GitHub\openvla\vla-scripts\finetune.py

# è®­ç»ƒ
d:\Stazica\Documents\GitHub\openvla\vla-scripts\train.py
```

---

### 4. æ•°æ®å¤„ç†

#### 4.1 RLDS æ•°æ®é›†é…ç½®
```
d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\
```

**å…³é”®æ–‡ä»¶**:

| æ–‡ä»¶ | è·¯å¾„ | ç”¨é€” |
|------|------|------|
| `oxe/configs.py` | `d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\configs.py` | æ•°æ®é›†é…ç½®ï¼ˆéœ€è¦æ·»åŠ ä½ çš„æ•°æ®é›†ï¼‰ |
| `oxe/transforms.py` | `d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\transforms.py` | æ•°æ®è½¬æ¢å‡½æ•°ï¼ˆéœ€è¦æ·»åŠ è½¬æ¢ï¼‰ |
| `oxe/mixtures.py` | `d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\mixtures.py` | æ•°æ®é›†æ··åˆé…ç½® |

**å¾®è°ƒæ—¶éœ€è¦ä¿®æ”¹**:
```python
# åœ¨ configs.py ä¸­æ·»åŠ ä½ çš„æœºå™¨äººæ•°æ®é›†é…ç½®
d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\configs.py

# åœ¨ transforms.py ä¸­æ·»åŠ ä½ çš„æ•°æ®è½¬æ¢å‡½æ•°
d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\transforms.py
```

---

### 5. è¯„ä¼°è„šæœ¬

```
d:\Stazica\Documents\GitHub\openvla\experiments\robot\
```

| æ–‡ä»¶ | è·¯å¾„ | ç”¨é€” |
|------|------|------|
| `widowx/eval_bridge_v2.py` | `d:\Stazica\Documents\GitHub\openvla\experiments\robot\widowx\eval_bridge_v2.py` | BridgeData V2 è¯„ä¼° |
| `libero/` | `d:\Stazica\Documents\GitHub\openvla\experiments\robot\libero\` | LIBERO æ¨¡æ‹Ÿè¯„ä¼° |

---

### 6. é¡¹ç›®é…ç½®æ–‡ä»¶

| æ–‡ä»¶ | è·¯å¾„ | ç”¨é€” |
|------|------|------|
| `pyproject.toml` | `d:\Stazica\Documents\GitHub\openvla\pyproject.toml` | é¡¹ç›®ä¾èµ–å’Œé…ç½® |
| `requirements-min.txt` | `d:\Stazica\Documents\GitHub\openvla\requirements-min.txt` | æœ€å°ä¾èµ–ï¼ˆæ¨ç†ç”¨ï¼‰ |
| `Makefile` | `d:\Stazica\Documents\GitHub\openvla\Makefile` | æ„å»ºå·¥å…· |

---

## ğŸš€ è¿ç§»åˆ°ä½ çš„é¡¹ç›®

### æ–¹æ¡ˆ A: æœ€å°åŒ–è¿ç§»ï¼ˆä»…æ¨ç†ï¼‰

**æ‰€éœ€æ–‡ä»¶**:
```
ä½ çš„é¡¹ç›®/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ openvla-7b/           # ä» huggingface/ å¤åˆ¶
â”œâ”€â”€ prismatic/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vla/
â”‚   â””â”€â”€ extern/hf/
â”œâ”€â”€ inference.py              # ä½¿ç”¨ demo_local.py çš„ä»£ç 
â””â”€â”€ requirements.txt          # ä» requirements-min.txt å¤åˆ¶
```

**ä»£ç ç¤ºä¾‹**:
```python
import sys
import os

# æ·»åŠ  OpenVLA è·¯å¾„
openvla_path = "d:/Stazica/Documents/GitHub/openvla"
sys.path.insert(0, openvla_path)

from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image
import torch

# åŠ è½½æœ¬åœ°æ¨¡å‹
model_path = "d:/Stazica/Documents/GitHub/openvla/huggingface"
processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)

model = AutoModelForVision2Seq.from_pretrained(
    model_path,
    torch_dtype=torch.float32,
    low_cpu_mem_usage=True,
    trust_remote_code=True,
    local_files_only=True
)

# æ¨ç†
image = Image.open("your_image.jpg")
prompt = "In: pick up the object\nOut:"
inputs = processor(prompt, image).to("cpu", dtype=torch.float32)

with torch.no_grad():
    action = model.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)

print(action)
```

---

### æ–¹æ¡ˆ B: å®Œæ•´è¿ç§»ï¼ˆæ¨ç† + å¾®è°ƒï¼‰

**æ‰€éœ€æ–‡ä»¶**:
```
ä½ çš„é¡¹ç›®/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ openvla-7b/           # ä» huggingface/ å¤åˆ¶
â”œâ”€â”€ prismatic/                 # å®Œæ•´å¤åˆ¶
â”œâ”€â”€ vla-scripts/               # å¤åˆ¶ train.py, finetune.py, deploy.py
â”œâ”€â”€ pyproject.toml            # å¤åˆ¶
â”œâ”€â”€ requirements-min.txt       # å¤åˆ¶
â””â”€â”€ your_data/                # ä½ çš„æœºå™¨äººæ•°æ®
    â””â”€â”€ rlds_datasets/
```

**å®‰è£…ä¾èµ–**:
```bash
pip install -r d:/Stazica/Documents/GitHub/openvla/requirements-min.txt
```

---

### æ–¹æ¡ˆ C: åŸåœ°ä½¿ç”¨ï¼ˆæ¨èï¼‰

ç›´æ¥åœ¨åŸé¡¹ç›®ä¸­å·¥ä½œï¼Œåªéœ€æ·»åŠ ä½ çš„ä»£ç å’Œæ•°æ®ï¼š

```
d:\Stazica\Documents\GitHub\openvla\
â”œâ”€â”€ huggingface/              # æ¨¡å‹ï¼ˆå·²æœ‰ï¼‰
â”œâ”€â”€ prismatic/                # æ ¸å¿ƒä»£ç ï¼ˆå·²æœ‰ï¼‰
â”œâ”€â”€ vla-scripts/              # è„šæœ¬ï¼ˆå·²æœ‰ï¼‰
â”œâ”€â”€ your_robot_code.py        # ä½ çš„æœºå™¨äººæ¥å£ä»£ç 
â””â”€â”€ your_data/                # ä½ çš„æ•°æ®é›†
    â””â”€â”€ rlds/
```

---

## ğŸ“‹ ç¯å¢ƒé…ç½®æ€»ç»“

### å·²å®‰è£…çš„ä¾èµ–

| åŒ… | ç‰ˆæœ¬ | ç”¨é€” |
|---|------|------|
| Python | 3.12.4 | è¿è¡Œç¯å¢ƒ |
| PyTorch | 2.9.1+cpu | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| Transformers | 4.40.1 | HuggingFace æ¨¡å‹åº“ |
| timm | 0.9.10 | è§†è§‰æ¨¡å‹åº“ |
| tokenizers | 0.19.1 | Tokenizer |
| accelerate | æœ€æ–°ç‰ˆæœ¬ | åˆ†å¸ƒå¼è®­ç»ƒ |
| pillow | æœ€æ–°ç‰ˆæœ¬ | å›¾åƒå¤„ç† |

### å®‰è£…å‘½ä»¤ï¼ˆåœ¨æ–°ç¯å¢ƒä¸­ï¼‰
```bash
# ä» OpenVLA é¡¹ç›®å¤åˆ¶ requirements æ–‡ä»¶
pip install torch transformers timm tokenizers accelerate pillow

# æˆ–ä½¿ç”¨ requirements-min.txt
pip install -r d:/Stazica/Documents/GitHub/openvla/requirements-min.txt
```

---

## ğŸ”— å…³é”®è·¯å¾„é€ŸæŸ¥è¡¨

| ç”¨é€” | è·¯å¾„ |
|------|------|
| **æœ¬åœ°æ¨¡å‹** | `d:\Stazica\Documents\GitHub\openvla\huggingface\` |
| **æ¨ç†æ¼”ç¤º** | `d:\Stazica\Documents\GitHub\openvla\demo_local.py` |
| **è‡ªå®šä¹‰æ¨ç†** | `d:\Stazica\Documents\GitHub\openvla\demo_custom.py` |
| **æ ¸å¿ƒä»£ç ** | `d:\Stazica\Documents\GitHub\openvla\prismatic\` |
| **å¾®è°ƒè„šæœ¬** | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\finetune.py` |
| **éƒ¨ç½²è„šæœ¬** | `d:\Stazica\Documents\GitHub\openvla\vla-scripts\deploy.py` |
| **æ•°æ®é›†é…ç½®** | `d:\Stazica\Documents\GitHub\openvla\prismatic\vla\datasets\rlds\oxe\configs.py` |
| **ä¾èµ–åˆ—è¡¨** | `d:\Stazica\Documents\GitHub\openvla\requirements-min.txt` |
| **é¡¹ç›®é…ç½®** | `d:\Stazica\Documents\GitHub\openvla\pyproject.toml` |

---

## ğŸ’¡ å¿«é€Ÿå¼€å§‹ä»£ç æ¨¡æ¿

### æ¨ç†æ¨¡æ¿

```python
import sys
import os
import torch
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image

# è®¾ç½®è·¯å¾„
OPENVLA_ROOT = r"d:\Stazica\Documents\GitHub\openvla"
sys.path.insert(0, OPENVLA_ROOT)

# åŠ è½½æ¨¡å‹
MODEL_PATH = os.path.join(OPENVLA_ROOT, "huggingface")

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
dtype = torch.float32 if device.type == "cpu" else torch.bfloat16

processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True, local_files_only=True)
model = AutoModelForVision2Seq.from_pretrained(
    MODEL_PATH, torch_dtype=dtype, low_cpu_mem_usage=True,
    trust_remote_code=True, local_files_only=True
).to(device)

# æ¨ç†å‡½æ•°
def predict_action(image_path, instruction):
    image = Image.open(image_path).convert("RGB")
    prompt = f"In: {instruction}\nOut:"
    inputs = processor(prompt, image).to(device, dtype=dtype)

    with torch.no_grad():
        action = model.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)

    return action.numpy()

# ä½¿ç”¨
action = predict_action("image.jpg", "pick up the red cup")
print(f"Action: {action}")
```

---

## ğŸ“š æ–‡æ¡£è·¯å¾„

| æ–‡æ¡£ | è·¯å¾„ |
|------|------|
| é¡¹ç›®è¯´æ˜ | `d:\Stazica\Documents\GitHub\openvla\README.md` |
| å¿«é€Ÿå¼€å§‹ | `d:\Stazica\Documents\GitHub\openvla\QUICKSTART.md` |
| æœ¬åœ°æŒ‡å— | `d:\Stazica\Documents\GitHub\openvla\quickstart_guide.md` |
| è¿ç§»æŒ‡å— | `d:\Stazica\Documents\GitHub\openvla\MIGRATION_GUIDE.md` (æœ¬æ–‡ä»¶) |

---

## âœ… è¿ç§»æ£€æŸ¥æ¸…å•

### æœ€å°åŒ–è¿ç§»ï¼ˆæ¨ç†ï¼‰
- [ ] å¤åˆ¶ `huggingface/` åˆ°æ–°é¡¹ç›®
- [ ] å¤åˆ¶ `prismatic/models/` åˆ°æ–°é¡¹ç›®
- [ ] å¤åˆ¶ `prismatic/vla/` åˆ°æ–°é¡¹ç›®
- [ ] å¤åˆ¶ `prismatic/extern/hf/` åˆ°æ–°é¡¹ç›®
- [ ] å®‰è£… `requirements-min.txt` ä¸­çš„ä¾èµ–
- [ ] ä½¿ç”¨ `demo_local.py` ä»£ç æ¨¡æ¿

### å®Œæ•´è¿ç§»ï¼ˆå¾®è°ƒï¼‰
- [ ] å¤åˆ¶æ•´ä¸ª `prismatic/` ç›®å½•
- [ ] å¤åˆ¶ `vla-scripts/` (train.py, finetune.py, deploy.py)
- [ ] å¤åˆ¶ `pyproject.toml`
- [ ] å®‰è£…æ‰€æœ‰ä¾èµ–ï¼ˆåŒ…æ‹¬ TensorFlow ç”¨äº RLDSï¼‰
- [ ] åœ¨ `configs.py` ä¸­æ·»åŠ ä½ çš„æ•°æ®é›†é…ç½®
- [ ] åœ¨ `transforms.py` ä¸­æ·»åŠ æ•°æ®è½¬æ¢å‡½æ•°
- [ ] å‡†å¤‡ RLDS æ ¼å¼çš„æœºå™¨äººæ•°æ®

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **é€‰æ‹©è¿ç§»æ–¹æ¡ˆ**ï¼ˆA/B/Cï¼‰
2. **å¤åˆ¶å¿…è¦æ–‡ä»¶**åˆ°æ–°é¡¹ç›®
3. **å®‰è£…ä¾èµ–**åˆ°æ–°ç¯å¢ƒ
4. **æµ‹è¯•æ¨ç†**ä½¿ç”¨ `demo_local.py` ä»£ç 
5. **ï¼ˆå¯é€‰ï¼‰å‡†å¤‡æ•°æ®é›†**ç”¨äºå¾®è°ƒ
6. **ï¼ˆå¯é€‰ï¼‰è¿è¡Œå¾®è°ƒ**ä½¿ç”¨ `finetune.py`

---

**æœ€åæ›´æ–°**: 2026-02-14
**OpenVLA ç‰ˆæœ¬**: openvla-7b
