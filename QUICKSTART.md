# OpenVLA å¿«é€Ÿå…¥é—¨æŒ‡å—

æ¬¢è¿å­¦ä¹  OpenVLAï¼æœ¬æŒ‡å—å°†å¸®åŠ©ä½ å¿«é€Ÿä¸Šæ‰‹å¹¶è¿è¡Œç¬¬ä¸€ä¸ªæ¨ç†ç¤ºä¾‹ã€‚

---

## ğŸ“‹ å‰ç½®è¦æ±‚

### å¿…éœ€
- Python >= 3.8
- condaï¼ˆAnaconda æˆ– Minicondaï¼‰
- çº¦ 15GB ç£ç›˜ç©ºé—´ï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰

### æ¨è
- NVIDIA GPUï¼ˆè‡³å°‘ 16GB æ˜¾å­˜ï¼Œæ¨è A100 80GBï¼‰
- CUDA 12.1+

---

## ğŸš€ å¿«é€Ÿå®‰è£…

### Windows ç”¨æˆ·

åœ¨ PowerShell ä¸­è¿è¡Œï¼š

```powershell
# è¿è¡Œå®‰è£…è„šæœ¬
.\install_and_test.ps1

# å¦‚æœé‡åˆ°æ‰§è¡Œç­–ç•¥é™åˆ¶ï¼Œå…ˆè¿è¡Œï¼š
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### Linux/Mac ç”¨æˆ·

åœ¨ç»ˆç«¯ä¸­è¿è¡Œï¼š

```bash
# è¿è¡Œå®‰è£…è„šæœ¬
chmod +x install_and_test.sh
./install_and_test.sh
```

### æ‰‹åŠ¨å®‰è£…ï¼ˆå¯é€‰ï¼‰

å¦‚æœå®‰è£…è„šæœ¬ä¸å·¥ä½œï¼Œå¯ä»¥æ‰‹åŠ¨æ‰§è¡Œï¼š

```bash
# 1. åˆ›å»ºå¹¶æ¿€æ´» conda ç¯å¢ƒ
conda create -n openvla python=3.10 -y
conda activate openvla

# 2. å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„å¹³å°é€‰æ‹©ï¼‰
# CUDA ç‰ˆæœ¬ï¼ˆæœ‰ NVIDIA GPUï¼‰
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# CPU ç‰ˆæœ¬ï¼ˆæ—  GPUï¼‰
conda install pytorch torchvision torchaudio cpuonly -c pytorch -y

# 3. å®‰è£…æœ€å°ä¾èµ–
pip install -r requirements-min.txt

# 4. å®‰è£… OpenVLA åŒ…ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
pip install -e .

# 5. å¯é€‰ï¼šå®‰è£… Flash Attention 2ï¼ˆä»… CUDAï¼‰
pip install packaging ninja
ninja --version
pip install "flash-attn==2.5.5" --no-build-isolation
```

---

## ğŸ¯ è¿è¡Œæ¼”ç¤º

### æ–¹å¼ 1ï¼šè‡ªåŠ¨æ¼”ç¤ºï¼ˆæ¨èé¦–æ¬¡ä½¿ç”¨ï¼‰

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate openvla

# è¿è¡Œè‡ªåŠ¨æ¼”ç¤º
python quickstart_demo.py
```

è¿™å°†ï¼š
- æ£€æŸ¥ GPU å¯ç”¨æ€§
- ä¸‹è½½ OpenVLA-7B æ¨¡å‹ï¼ˆçº¦ 14GBï¼‰
- åˆ›å»ºæµ‹è¯•å›¾åƒ
- å¯¹å¤šä¸ªä»»åŠ¡æŒ‡ä»¤è¿›è¡Œæ¨ç†
- æ˜¾ç¤ºé¢„æµ‹çš„ 7-DoF åŠ¨ä½œ

### æ–¹å¼ 2ï¼šäº¤äº’æ¨¡å¼ï¼ˆä½¿ç”¨ä½ è‡ªå·±çš„å›¾åƒï¼‰

```bash
conda activate openvla
python quickstart_demo.py interactive
```

è¿™å°†ï¼š
- è®©ä½ æä¾›è‡ªå·±çš„å›¾åƒæ–‡ä»¶
- è¾“å…¥è‡ªå®šä¹‰çš„ä»»åŠ¡æŒ‡ä»¤
- å®æ—¶é¢„æµ‹å¹¶æ˜¾ç¤ºåŠ¨ä½œ

---

## ğŸ“Š è¾“å‡ºè¯´æ˜

### åŠ¨ä½œæ ¼å¼ï¼ˆ7-DoFï¼‰

```
ä½ç½® (XYZ):
  x: <ä½ç½® X>
  y: <ä½ç½® Y>
  z: <ä½ç½® Z>

æ—‹è½¬ (RPY):
  roll:  <æ»šè½¬è§’åº¦>
  pitch: <ä¿¯ä»°è§’åº¦>
  yaw:   <åèˆªè§’åº¦>

å¤¹çˆª:
  state: <0=closed, 1=open>
```

### æ¨ç†é€Ÿåº¦å‚è€ƒ

- **A100 80GB**: ~50-100 ms/åŠ¨ä½œ
- **RTX 3090**: ~100-200 ms/åŠ¨ä½œ
- **RTX 3080**: ~150-250 ms/åŠ¨ä½œ
- **CPU**: ~5-10 s/åŠ¨ä½œ

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: æ¨¡å‹ä¸‹è½½å¾ˆæ…¢æˆ–å¤±è´¥ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨é•œåƒæºé…ç½® HuggingFace
2. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹å¹¶æ”¾åœ¨æœ¬åœ°ç›®å½•
3. ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚ openvla-v01-7bï¼‰

```python
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
model_path = "/path/to/local/model"
vla = AutoModelForVision2Seq.from_pretrained(model_path, ...)
```

### Q2: æ˜¾å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨ä½ç²¾åº¦æ¨ç†
vla = AutoModelForVision2Seq.from_pretrained(
    "openvla/openvla-7b",
    torch_dtype=torch.float16,  # æˆ– torch.float32
    low_cpu_mem_usage=True,
    ...
)

# æˆ–ä½¿ç”¨ CPU
device = "cpu"
```

### Q3: Flash Attention å®‰è£…å¤±è´¥ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**:
Flash Attention æ˜¯å¯é€‰çš„ï¼Œä¸å®‰è£…ä¹Ÿèƒ½è¿è¡Œï¼Œåªæ˜¯æ¨ç†é€Ÿåº¦ç¨æ…¢ã€‚å¯ä»¥è·³è¿‡è¯¥æ­¥éª¤ç»§ç»­ä½¿ç”¨ã€‚

### Q4: æ¨ç†ç»“æœä¸åˆç†ï¼Ÿ

**åŸå› **:
- ä½¿ç”¨éšæœºæµ‹è¯•å›¾åƒï¼Œæ¨¡å‹æ— æ³•ç†è§£åœºæ™¯
- éœ€è¦ä½¿ç”¨çœŸå®çš„æœºå™¨äººè§†è§’å›¾åƒ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨äº¤äº’æ¨¡å¼ï¼Œæä¾›çœŸå®çš„æœºå™¨äººå›¾åƒ
python quickstart_demo.py interactive
```

---

## ğŸ“š ä¸‹ä¸€æ­¥å­¦ä¹ 

### 1. ç†è§£æ¨¡å‹æ¶æ„
- æŸ¥çœ‹ `prismatic/models/` ç›®å½•
- é˜…è¯»æ¨¡å‹å®šä¹‰æ–‡ä»¶

### 2. å­¦ä¹ å¾®è°ƒ
- é˜…è¯» `vla-scripts/finetune.py`
- å‡†å¤‡ä½ è‡ªå·±çš„æ•°æ®é›†
- è¿è¡Œ LoRA å¾®è°ƒ

### 3. éƒ¨ç½²åˆ°æœºå™¨äºº
- è¿è¡Œ `vla-scripts/deploy.py` å¯åŠ¨ REST API
- ç¼–å†™æœºå™¨äººæ§åˆ¶è„šæœ¬è°ƒç”¨ API

### 4. æ·±å…¥ç ”ç©¶
- é˜…è¯» `README.md` çš„å®Œæ•´æ–‡æ¡£
- æŸ¥çœ‹ `experiments/` ä¸­çš„è¯„ä¼°è„šæœ¬
- ç ”ç©¶è®ºæ–‡: https://arxiv.org/abs/2406.09246

---

## ğŸ“ ç¤ºä¾‹ä»£ç 

### ç®€å•æ¨ç†ç¤ºä¾‹

```python
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image
import torch

# åŠ è½½æ¨¡å‹
processor = AutoProcessor.from_pretrained("openvla/openvla-7b", trust_remote_code=True)
vla = AutoModelForVision2Seq.from_pretrained(
    "openvla/openvla-7b", 
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
).to("cuda:0")

# å‡†å¤‡è¾“å…¥
image = Image.open("robot_view.jpg")
prompt = "In: What action should the robot take to pick up the red cup?\nOut:"

# é¢„æµ‹åŠ¨ä½œ
inputs = processor(prompt, image).to("cuda:0", dtype=torch.bfloat16)
action = vla.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)

print(f"é¢„æµ‹åŠ¨ä½œ: {action}")
```

### æ‰¹é‡æ¨ç†

```python
import torch
from transformers import AutoModelForVision2Seq, AutoProcessor
from PIL import Image

processor = AutoProcessor.from_pretrained("openvla/openvla-7b", trust_remote_code=True)
vla = AutoModelForVision2Seq.from_pretrained(
    "openvla/openvla-7b", 
    torch_dtype=torch.bfloat16,
    trust_remote_code=True
).to("cuda:0")

# å¤šä¸ªä»»åŠ¡
tasks = [
    ("image1.jpg", "pick up the red cup"),
    ("image2.jpg", "push the blue block"),
    ("image3.jpg", "open the drawer"),
]

for image_path, instruction in tasks:
    image = Image.open(image_path)
    prompt = f"In: What action should the robot take to {instruction.lower()}?\nOut:"
    inputs = processor(prompt, image).to("cuda:0", dtype=torch.bfloat16)
    action = vla.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)
    print(f"{instruction}: {action}")
```

---

## ğŸ“– å‚è€ƒèµ„æº

- **é¡¹ç›®ä¸»é¡µ**: https://github.com/openvla/openvla
- **è®ºæ–‡**: https://arxiv.org/abs/2406.09246
- **HuggingFace**: https://huggingface.co/openvla
- **é¡¹ç›®ç½‘ç«™**: https://openvla.github.io/

---

## ğŸ’¡ æç¤º

- é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
- å¦‚æœæ²¡æœ‰ GPUï¼Œæ¨ç†é€Ÿåº¦ä¼šå¾ˆæ…¢ï¼Œä½†åŠŸèƒ½å®Œå…¨æ­£å¸¸
- ä½¿ç”¨çœŸå®æœºå™¨äººè§†è§’å›¾åƒä¼šå¾—åˆ°æ›´åˆç†çš„åŠ¨ä½œé¢„æµ‹
- å»ºè®®ä»ç®€å•çš„ä»»åŠ¡å¼€å§‹ï¼Œé€æ­¥å°è¯•æ›´å¤æ‚çš„æŒ‡ä»¤

---

## ğŸ†˜ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé‡åˆ°é—®é¢˜ï¼š
1. æŸ¥çœ‹æœ¬æŒ‡å—çš„"å¸¸è§é—®é¢˜"éƒ¨åˆ†
2. æ£€æŸ¥ README.md çš„è¯¦ç»†æ–‡æ¡£
3. åœ¨ GitHub Issues ä¸­æœç´¢ç±»ä¼¼é—®é¢˜
4. åˆ›å»ºæ–°çš„ Issue æè¿°ä½ çš„é—®é¢˜

---

ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸ‰
